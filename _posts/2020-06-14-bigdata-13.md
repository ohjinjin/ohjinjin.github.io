---
title: "Operation of Dataset(2)-Understading BigData(12)"
categories: 
  - BigData
last_modified_at: 2020-06-14T14:38:00+09:00
toc: true
---

Intro
---
학교 수강과목에서 학습한 내용을 복습하는 용도의 포스트입니다.<br/>
빅데이터 개념과 오픈소스인 아파치 하둡과 맵리듀스 및 스파크를 이용한 빅데이터 적용을 공부합니다.<br/>
맵 리듀스의 경우 사용하기에 다소 진입장벽이 있는편입니다.<br/> 스파크처럼 통합 환경을 제공하지 않아 원하는 유틸리티나 라이브러리를 별도로 연결해서 사용해야하기 때문입니다. 이를 해소하는 것이 스파크라는 분산 데이터 처리 통합 엔진입니다.<br/>
따라서 맵 리듀스로 먼저 공부해보고, 스파크로 넘어갑니다.<br/>

스파크 엔진의 경우 Java가 아닌 Scalar라는 언어로 사용하며, 기존 우리가 알고 있는 SQL을 통해 고급 질의가 가능하며, 시각화나 스트림 처리 및 기계학습등 까지의 높은 수준의 분석을 제공하는 통합 프레임 워크입니다.<br/>

빅데이터 컴퓨팅(분산시스템상의 분산처리 환경)의 기본 개념과 원리를 이해하고 이를 실습해보는 과정에서 2대 이상의 리눅스 클러스터 서버를 구축 및 활용할 것입니다.<br/>

[빅데이터이해(1) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-1/)<br/>
[빅데이터이해(2) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-2/)<br/>
[빅데이터이해(3) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-3/)<br/>
[빅데이터이해(4) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-4/)<br/>
[빅데이터이해(5) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-5/)<br/>
[빅데이터이해(6) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-6/)<br/>
[빅데이터이해(7) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-7/)<br/>
[빅데이터이해(8) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-8/)<br/>
[빅데이터이해(9) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-9/)<br/>
[빅데이터이해(10) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-10/)<br/>
[빅데이터이해(11) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-11/)<br/>
[빅데이터이해(12) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-12/)<br/>

이번 시간에는 지난 시간에 이어서 스파크 데이터세트의 연산에 대해 배웁니다.<br/>

Operation of Dataset
---
이번 시간엔 데이터 캐싱과 사용자 정의 함수를 정의하여 적용하는 예를 학습하겠습니다.<br/>

지난 시간 스파크의 기본연산을 배웠을 때 데이터 프레임 또는 데이터 세트로부터 변환 연산을 적용하고 액션을 수행하는 과정을 배웠습니다.<br/>
그리고 액션을 수행하기 전까지는 변환을 적용하지 않고 계보 그래프로 나타내고 있는 **지연연산수행**을 제공한다는 것을 배웠습니다.<br/>

데이터 세트 액션 수행 전까지는 베이스 데이터세트가 생성되지 않으며 스파크는 데이터세트 액션을 수행할 때마다 데이터세트와 모든 관련 종속연산을 다시 계산한다는 것이지요.<br/>

변환을 적용해놓은 것에 대해 액션을 수행할 때 부모에 대한 데이터 세트도 계보그래프를 통해 다시 계산을해서 액션을 수행하게 됩니다.<br/>


액션이 호출될 때 데이터가 실제로 생성되고나서 해당 액션이 실행되는데 액션 값이 리턴되고나면 디폴트로 변환된 데이터세트는 메모리에서 제거가 됩니다.<br/>

그래서 또 다른 연산을 하려고 하면 다시 계산을 하게 됩니다.<br/>
따라서 중복된 계산을 수행하게되고 실행 시 성능에 부담이 많이 되겠지요.<br/>

그래서 메모리에서 제거하지 않고 연산을 이어서 재사용하며 수행할 수 있다면 보다 빠른 성능을 기대할 수 있겠지요.<br/>

이러한 데이터세트 캐싱 절차는 아래와 같이 이루어지게 됩니다.<br/>
* 클래스 임포트<br/>
* 데이터세트 정의<br/>
* 변환 정의<br/>
* 데이터세트 캐싱<br/>
참고로 cache() 메소드를 사용하여 데이터세트를 메모리와 디스크에 캐싱하는데, persist(MEMORY_ONLY), persist(MEMORY_AND_DISK)등의 메소드를 사용할 수도 있습니다.<br/>
* 액션 적용<br/>
* 캐싱된 데이터를 이후 액션에도 적용<br/>
* 데이터세트 캐싱 해제<br/>
unpersist() 메소드를 사용하여 해제<br/>



